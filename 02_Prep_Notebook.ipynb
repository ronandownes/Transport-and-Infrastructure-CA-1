{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dublin Bike CA 1\n",
    "\n",
    "## 2 Preparation Notebook\n",
    "\n",
    "\n",
    "Ronan Downes December 2022 \n",
    "\n",
    "Prerequisite Notebook: **01_Load_Notebook**\n",
    "\n",
    "Successor Notebook: **03_MachineLearn_Notebook**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Might get annoying so clear current output if required\n",
    "# from IPython.display import Image\n",
    "# Image(filename =r'bike2.gif', width = 600, height = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and files do unique study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION ID                   111\n",
       "TIME                      103038\n",
       "LAST UPDATED             5039168\n",
       "NAME                         111\n",
       "BIKE STANDS                   18\n",
       "AVAILABLE BIKE STANDS         41\n",
       "AVAILABLE BIKES               41\n",
       "STATUS                         2\n",
       "ADDRESS                      111\n",
       "LATITUDE                     111\n",
       "LONGITUDE                    111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary libraries and files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "df4=  pd.read_csv('data/2021_Q4.csv')  ### For faster testing\n",
    "df = pd.read_csv('data/01_Loaded_Bikes.csv')\n",
    "dfw=pd.read_csv('data/01_Loaded_Weather.csv')\n",
    "dft = pd.read_csv(\"data/01_Loaded_Travel_2006.csv\")  \n",
    "dfT = pd.read_csv(\"data/01_Loaded_Travel_2011.csv\")\n",
    "df.nunique (axis=0, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          STATION ID                 TIME         LAST UPDATED  \\\n",
       "0                 2  2021-10-01 00:05:02  2021-10-01 00:00:15   \n",
       "1                 2  2021-10-01 00:10:02  2021-10-01 00:05:36   \n",
       "2                 2  2021-10-01 00:15:02  2021-10-01 00:05:36   \n",
       "3                 2  2021-10-01 00:20:02  2021-10-01 00:15:43   \n",
       "4                 2  2021-10-01 00:25:02  2021-10-01 00:15:43   \n",
       "...             ...                  ...                  ...   \n",
       "2776080         507  2022-01-01 23:35:02  2021-11-18 07:11:16   \n",
       "2776081         507  2022-01-01 23:40:02  2021-11-18 07:11:16   \n",
       "2776082         507  2022-01-01 23:45:02  2021-11-18 07:11:16   \n",
       "2776083         507  2022-01-01 23:50:02  2021-11-18 07:11:16   \n",
       "2776084         507  2022-01-01 23:55:02  2021-11-18 07:11:16   \n",
       "\n",
       "                               NAME  BIKE STANDS  AVAILABLE BIKE STANDS  \\\n",
       "0                BLESSINGTON STREET           20                      7   \n",
       "1                BLESSINGTON STREET           20                      6   \n",
       "2                BLESSINGTON STREET           20                      6   \n",
       "3                BLESSINGTON STREET           20                      6   \n",
       "4                BLESSINGTON STREET           20                      6   \n",
       "...                             ...          ...                    ...   \n",
       "2776080  ORIEL STREET TEST TERMINAL            1                      0   \n",
       "2776081  ORIEL STREET TEST TERMINAL            1                      0   \n",
       "2776082  ORIEL STREET TEST TERMINAL            1                      0   \n",
       "2776083  ORIEL STREET TEST TERMINAL            1                      0   \n",
       "2776084  ORIEL STREET TEST TERMINAL            1                      0   \n",
       "\n",
       "         AVAILABLE BIKES STATUS  \\\n",
       "0                     13   Open   \n",
       "1                     14   Open   \n",
       "2                     14   Open   \n",
       "3                     14   Open   \n",
       "4                     14   Open   \n",
       "...                  ...    ...   \n",
       "2776080                1   Open   \n",
       "2776081                1   Open   \n",
       "2776082                1   Open   \n",
       "2776083                1   Open   \n",
       "2776084                1   Open   \n",
       "\n",
       "                                                   ADDRESS  LATITUDE  \\\n",
       "0                                       Blessington Street  53.35677   \n",
       "1                                       Blessington Street  53.35677   \n",
       "2                                       Blessington Street  53.35677   \n",
       "3                                       Blessington Street  53.35677   \n",
       "4                                       Blessington Street  53.35677   \n",
       "...                                                    ...       ...   \n",
       "2776080  JCDecaux Ireland, 52 Oriel Street Lower, Dublin 1  53.35463   \n",
       "2776081  JCDecaux Ireland, 52 Oriel Street Lower, Dublin 1  53.35463   \n",
       "2776082  JCDecaux Ireland, 52 Oriel Street Lower, Dublin 1  53.35463   \n",
       "2776083  JCDecaux Ireland, 52 Oriel Street Lower, Dublin 1  53.35463   \n",
       "2776084  JCDecaux Ireland, 52 Oriel Street Lower, Dublin 1  53.35463   \n",
       "\n",
       "         LONGITUDE  \n",
       "0        -6.268140  \n",
       "1        -6.268140  \n",
       "2        -6.268140  \n",
       "3        -6.268140  \n",
       "4        -6.268140  \n",
       "...            ...  \n",
       "2776080  -6.242615  \n",
       "2776081  -6.242615  \n",
       "2776082  -6.242615  \n",
       "2776083  -6.242615  \n",
       "2776084  -6.242615  \n",
       "\n",
       "[2776085 rows x 11 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11283524 entries, 0 to 11283523\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   TIME                   object \n",
      " 2   LAST UPDATED           object \n",
      " 3   NAME                   object \n",
      " 4   BIKE STANDS            int64  \n",
      " 5   AVAILABLE BIKE STANDS  int64  \n",
      " 6   AVAILABLE BIKES        int64  \n",
      " 7   STATUS                 object \n",
      " 8   ADDRESS                object \n",
      " 9   LATITUDE               float64\n",
      " 10  LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 947.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION ID               0\n",
       "TIME                     0\n",
       "LAST UPDATED             0\n",
       "NAME                     0\n",
       "BIKE STANDS              0\n",
       "AVAILABLE BIKE STANDS    0\n",
       "AVAILABLE BIKES          0\n",
       "STATUS                   0\n",
       "ADDRESS                  0\n",
       "LATITUDE                 0\n",
       "LONGITUDE                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()   # Bike data has no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     0\n",
       "ind      0\n",
       "rain     0\n",
       "ind.1    0\n",
       "temp     0\n",
       "ind.2    0\n",
       "wetb     0\n",
       "dewpt    0\n",
       "vappr    0\n",
       "rhum     0\n",
       "msl      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfw.isnull().sum()   # Weather data has no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168408 entries, 0 to 168407\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   date    168408 non-null  object\n",
      " 1   ind     168408 non-null  int64 \n",
      " 2   rain    168408 non-null  object\n",
      " 3   ind.1   168408 non-null  int64 \n",
      " 4   temp    168408 non-null  object\n",
      " 5   ind.2   168408 non-null  int64 \n",
      " 6   wetb    168408 non-null  object\n",
      " 7   dewpt   168408 non-null  object\n",
      " 8   vappr   168408 non-null  object\n",
      " 9   rhum    168408 non-null  object\n",
      " 10  msl     168408 non-null  object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dfw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION ID                 int64\n",
       "TIME                      object\n",
       "LAST UPDATED              object\n",
       "NAME                      object\n",
       "BIKE STANDS                int64\n",
       "AVAILABLE BIKE STANDS      int64\n",
       "AVAILABLE BIKES            int64\n",
       "STATUS                    object\n",
       "ADDRESS                   object\n",
       "LATITUDE                 float64\n",
       "LONGITUDE                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate rows:  (94354, 11)\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate rows:  (0, 11)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     object\n",
       "ind       int64\n",
       "rain     object\n",
       "ind.1     int64\n",
       "temp     object\n",
       "ind.2     int64\n",
       "wetb     object\n",
       "dewpt    object\n",
       "vappr    object\n",
       "rhum     object\n",
       "msl      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate rows:  (0, 11)\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows_dfw = dfw[dfw.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_dfw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>On_foot</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90982</td>\n",
       "      <td>329684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17516</td>\n",
       "      <td>131129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24561</td>\n",
       "      <td>168832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28469</td>\n",
       "      <td>171559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   On_foot   Total\n",
       "0    90982  329684\n",
       "1    17516  131129\n",
       "2    24561  168832\n",
       "3    28469  171559"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv(\"data/01_Loaded_Travel_2006.csv\",usecols = ['On_foot','Total'])\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2006_Census</th>\n",
       "      <th>On_foot</th>\n",
       "      <th>Bicycle</th>\n",
       "      <th>Bus_minibus_coach</th>\n",
       "      <th>Train_DART_LUAS</th>\n",
       "      <th>Motorcycle_scooter</th>\n",
       "      <th>Car_Driver</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Other</th>\n",
       "      <th>Not_stated</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dublin City</td>\n",
       "      <td>90982</td>\n",
       "      <td>18028</td>\n",
       "      <td>63101</td>\n",
       "      <td>18138</td>\n",
       "      <td>2806</td>\n",
       "      <td>85128</td>\n",
       "      <td>24346</td>\n",
       "      <td>16381</td>\n",
       "      <td>10774</td>\n",
       "      <td>329684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dún Laoghaire-Rathdown</td>\n",
       "      <td>17516</td>\n",
       "      <td>4995</td>\n",
       "      <td>15668</td>\n",
       "      <td>13629</td>\n",
       "      <td>1276</td>\n",
       "      <td>50180</td>\n",
       "      <td>19778</td>\n",
       "      <td>6813</td>\n",
       "      <td>1274</td>\n",
       "      <td>131129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fingal</td>\n",
       "      <td>24561</td>\n",
       "      <td>3220</td>\n",
       "      <td>20332</td>\n",
       "      <td>16938</td>\n",
       "      <td>1318</td>\n",
       "      <td>69244</td>\n",
       "      <td>20520</td>\n",
       "      <td>9357</td>\n",
       "      <td>3342</td>\n",
       "      <td>168832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Dublin</td>\n",
       "      <td>28469</td>\n",
       "      <td>4662</td>\n",
       "      <td>26246</td>\n",
       "      <td>3148</td>\n",
       "      <td>1888</td>\n",
       "      <td>71663</td>\n",
       "      <td>21452</td>\n",
       "      <td>10801</td>\n",
       "      <td>3230</td>\n",
       "      <td>171559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2006_Census  On_foot  Bicycle  Bus_minibus_coach  \\\n",
       "0             Dublin City    90982    18028              63101   \n",
       "1  Dún Laoghaire-Rathdown    17516     4995              15668   \n",
       "2                  Fingal    24561     3220              20332   \n",
       "3            South Dublin    28469     4662              26246   \n",
       "\n",
       "   Train_DART_LUAS  Motorcycle_scooter  Car_Driver   Car_Passenger  Other  \\\n",
       "0            18138                2806       85128           24346  16381   \n",
       "1            13629                1276       50180           19778   6813   \n",
       "2            16938                1318       69244           20520   9357   \n",
       "3             3148                1888       71663           21452  10801   \n",
       "\n",
       "   Not_stated   Total  \n",
       "0       10774  329684  \n",
       "1        1274  131129  \n",
       "2        3342  168832  \n",
       "3        3230  171559  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv(\"data/01_Loaded_Travel_2006.csv\")  \n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2006_Census</th>\n",
       "      <th>On_foot</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dublin City</td>\n",
       "      <td>90982</td>\n",
       "      <td>329684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dún Laoghaire-Rathdown</td>\n",
       "      <td>17516</td>\n",
       "      <td>131129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fingal</td>\n",
       "      <td>24561</td>\n",
       "      <td>168832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Dublin</td>\n",
       "      <td>28469</td>\n",
       "      <td>171559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2006_Census  On_foot   Total\n",
       "0             Dublin City    90982  329684\n",
       "1  Dún Laoghaire-Rathdown    17516  131129\n",
       "2                  Fingal    24561  168832\n",
       "3            South Dublin    28469  171559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv(\"data/01_Loaded_Travel_2006.csv\",usecols = ['2006_Census','On_foot','Total'])\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2006_Census</th>\n",
       "      <th>On_foot</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dublin City</td>\n",
       "      <td>90982</td>\n",
       "      <td>329684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dún Laoghaire-Rathdown</td>\n",
       "      <td>17516</td>\n",
       "      <td>131129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fingal</td>\n",
       "      <td>24561</td>\n",
       "      <td>168832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Dublin</td>\n",
       "      <td>28469</td>\n",
       "      <td>171559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2006_Census  On_foot   Total\n",
       "0             Dublin City    90982  329684\n",
       "1  Dún Laoghaire-Rathdown    17516  131129\n",
       "2                  Fingal    24561  168832\n",
       "3            South Dublin    28469  171559"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11189170 entries, 0 to 11283523\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   TIME                   object \n",
      " 2   LAST UPDATED           object \n",
      " 3   NAME                   object \n",
      " 4   BIKE STANDS            int64  \n",
      " 5   AVAILABLE BIKE STANDS  int64  \n",
      " 6   AVAILABLE BIKES        int64  \n",
      " 7   STATUS                 object \n",
      " 8   ADDRESS                object \n",
      " 9   LATITUDE               float64\n",
      " 10  LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()   # 947MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     168408\n",
       "ind           2\n",
       "rain        185\n",
       "ind.1         2\n",
       "temp        706\n",
       "ind.2         2\n",
       "wetb        578\n",
       "dewpt       592\n",
       "vappr       388\n",
       "rhum        152\n",
       "msl        1640\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfw.nunique (axis=0, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     dfs.columns = dfs.columns.str.replace(' ','_')\n",
    "#     dfs.columns = dfs.columns.str.lower()\n",
    "#     dfs.columns = dfs.columns.str.capitalize()\n",
    "#     return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.drop(['STATUS','TIME'], axis=1, inplace=True)  # Status is always open so is dropped \n",
    "# and at The temporal resolution of this study \"time\" CAN BE DROPPED\n",
    "df.drop_duplicates(keep= 'first',inplace=True)    \n",
    "#remove rows where no bike has been taken or returned since previous readings\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows where no bike has been taken or returned since previous readings\n",
    "df.drop_duplicates(keep= 'first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6222487 entries, 0 to 11283233\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   LAST UPDATED           object \n",
      " 2   NAME                   object \n",
      " 3   BIKE STANDS            int64  \n",
      " 4   AVAILABLE BIKE STANDS  int64  \n",
      " 5   AVAILABLE BIKES        int64  \n",
      " 6   ADDRESS                object \n",
      " 7   LATITUDE               float64\n",
      " 8   LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 474.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #memory usage: 474.7+ MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filter to available post COVID-19 lockdoown  dates and removes duplicate rows\n",
    "Usage of the DataFrame.loc[] Method to Filter Data to interval of interest and drop the \"TIME\" feature because it is reduntant.\n",
    "\n",
    "The aim is to plan rebalancing and growth based on ML models so COVID-19 lockdown and xmas Holidays are ommitted.\n",
    "Memory usage is 685 MB after Date filter and before merging weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4188876 entries, 3109999 to 10611332\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   STATION ID             int64  \n",
      " 1   LAST UPDATED           object \n",
      " 2   NAME                   object \n",
      " 3   BIKE STANDS            int64  \n",
      " 4   AVAILABLE BIKE STANDS  int64  \n",
      " 5   AVAILABLE BIKES        int64  \n",
      " 6   ADDRESS                object \n",
      " 7   LATITUDE               float64\n",
      " 8   LONGITUDE              float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 319.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4188876, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2021-04-12'    #Lockdown restrictions lifted\n",
    "end_date = '2021-12-11'      # Traditiona date for beginning of xmas holidays \n",
    "after_start_date = df['LAST UPDATED'] >= start_date\n",
    "before_end_date = df['LAST UPDATED'] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "# Using pandas.DataFrame.loc to Filter Rows by Dates\n",
    "df = df.loc[between_two_dates]\n",
    "df.drop_duplicates(keep= 'first',inplace=True)\n",
    "df.info()   #memory usage: 319.6+ MB\n",
    "df.shape # shape is (4188876, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q4df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# df.columns = df.columns.str.replace(' ','_')\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# df.columns = df.columns.str.lower()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# df.columns = df.columns.str.capitalize()\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mq4df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'q4df' is not defined"
     ]
    }
   ],
   "source": [
    "#User-defined functions\n",
    "\n",
    "\n",
    "def dfsnake (dfs):\n",
    "    dfs.columns = dfs.columns.str.replace(' ','_')\n",
    "    dfs.columns = dfs.columns.str.lower()\n",
    "    dfs.columns = dfs.columns.str.capitalize()\n",
    "    return\n",
    "\n",
    "# df.columns = df.columns.str.replace(' ','_')\n",
    "# df.columns = df.columns.str.lower()\n",
    "# df.columns = df.columns.str.capitalize()\n",
    "# q4df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q4df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsnake(q4df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "q4df.rename(columns={'Station_id':'Id',\"Bike_stands\": \"Total\", \"Available_bike_stands\": \"Docks\",\"Available_bikes\":\"Bikes\"}, inplace = True)\n",
    "q4df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split \"Last_updated\" to date and time columns\n",
    "df['Date_time'] = [dt.datetime.strptime(d, \"%Y-%m-%d %H:%M:%S\") for d in df[\"Last_updated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_updated'] = [dt.datetime.time(d) for d in df['Date_time']] \n",
    "df['Date'] = [dt.datetime.date(d) for d in df['Date_time']] \n",
    "df['Link_date'] = df['Date_time'].dt.round('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf.shape ##14.1+ MB  wdf.shape gives (168408, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bike_percentage'] =  100*(df['Available_bikes'] / df['Bike_stands'])\n",
    "df['Full'] = np.where(df['Bike_percentage'] == 0, 1,0 )\n",
    "df['Empty'] =np.where(df['Bike_percentage']== 1, 1,0 )\n",
    "df.sample(22)\n",
    "df.nunique (axis=0, dropna=True) #check that only one \"STATUS\" remains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weather with bikes data\n",
    "merged_data = pd.merge(data, weather, on = 'date_for_merge', how = 'left')\n",
    "\n",
    "# identify bike arrivals and bike departures\n",
    "merged_data['BIKE_ARR_DEP'] = merged_data.groupby('STATION ID')['AVAILABLE BIKE STANDS'].diff(-1)\n",
    "merged_data['BIKE_ARR'] = np.where(merged_data['BIKE_ARR_DEP'] > 0, merged_data['BIKE_ARR_DEP'], 0)\n",
    "merged_data['BIKE_DEP'] = np.where(merged_data['BIKE_ARR_DEP'] < 0, merged_data['BIKE_ARR_DEP'], 0)\n",
    "merged_data['ACTIVITY_TYPE'] = np.where(abs(merged_data['BIKE_ARR_DEP']) >= 10, \"REBALANCING\", \"RENTAL\")\n",
    "merged_data['IMBALANCED'] = np.where(merged_data['OCCUPANCY_PCT'] < .1, 1, \n",
    "                                   np.where(merged_data['OCCUPANCY_PCT'] > .9, 1,0 ))\n",
    "\n",
    "# Identify days with rebalancing\n",
    "merged_data['REBALANCING'] = np.where(merged_data['ACTIVITY_TYPE'] == 'REBALANCING', 1,0)\n",
    "merged_data['JOIN_ON'] = merged_data['STATION ID'].apply(str)  + (merged_data['DATE']).apply(str) \n",
    "join_table= merged_data.groupby(['JOIN_ON'])['REBALANCING'].sum()\n",
    "merged_data = merged_data.drop(['REBALANCING'], axis = 1)\n",
    "join_table = join_table.to_frame()\n",
    "join_table =join_table.reset_index()\n",
    "merged_data = pd.merge(merged_data, join_table, on = 'JOIN_ON', how = 'left')\n",
    "merged_data = merged_data.drop(['JOIN_ON'], axis = 1)\n",
    "\n",
    "merged_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data into clusters\n",
    "clustering_df = merged_data[['STATION ID', 'NAME', 'LATITUDE', 'LONGITUDE', 'DAY_TYPE', 'TIME_TYPE', 'OCCUPANCY_PCT','CLUSTER_GROUP']]\n",
    "clustering_df = clustering_df.groupby(['STATION ID', 'NAME', 'LATITUDE', 'LONGITUDE', 'CLUSTER_GROUP'],as_index=False)['OCCUPANCY_PCT'].mean()\n",
    "clustering_df  = clustering_df.set_index('STATION ID')\n",
    "\n",
    "#pivot dataframe for clustering\n",
    "clustering_df = clustering_df.pivot_table(index= ['NAME', 'STATION ID','LATITUDE', 'LONGITUDE'] , columns=['CLUSTER_GROUP'], values='OCCUPANCY_PCT')\n",
    "clustering_df  = clustering_df.reset_index()\n",
    "clustering_df  = clustering_df .set_index('NAME')\n",
    "clustering_df = clustering_df.dropna()\n",
    "\n",
    "clustering_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,10)\n",
    "X = np.array(clustering_df.drop(['STATION ID', 'LATITUDE', 'LONGITUDE'], 1).astype(float))\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(X)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering algo\n",
    "X = np.array(clustering_df.drop(['STATION ID', 'LATITUDE', 'LONGITUDE'], 1).astype(float))\n",
    "KM = KMeans(n_clusters=5) \n",
    "KM.fit(X)\n",
    "clusters = KM.predict(X)\n",
    "\n",
    "locations = clustering_df\n",
    "locations['Cluster'] = clusters\n",
    "locations = locations.reset_index()\n",
    "locations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {0: 'blue', 1: 'red', 2: 'orange', 3: 'green', 4: 'purple'}\n",
    "dublin_map = folium.Map([53.345, -6.2650], zoom_start=13.5)\n",
    "for LATITUDE, LONGITUDE, Cluster in zip(locations['LATITUDE'],locations['LONGITUDE'], locations['Cluster']):\n",
    "    folium.CircleMarker(\n",
    "        [LATITUDE, LONGITUDE],\n",
    "        color = 'b',\n",
    "        radius = 8,\n",
    "        fill_color=colordict[Cluster],\n",
    "        fill=True,\n",
    "        fill_opacity=0.9\n",
    "        ).add_to(dublin_map)\n",
    "dublin_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge clusters back into main dataset\n",
    "\n",
    "merged_with_clusters = merged_data\n",
    "cluster_output = locations[['STATION ID', 'Cluster']]\n",
    "cluster_output.drop_duplicates(keep = 'first', inplace = True)\n",
    "del merged_data\n",
    "merged_with_clusters = pd.merge (merged_with_clusters, cluster_output, on = 'STATION ID', how = 'left')\n",
    "merged_with_clusters['BIKE_ARR_DEP_ABS'] = abs(merged_with_clusters['BIKE_ARR_DEP'])\n",
    "merged_with_clusters.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linechart_data = merged_with_clusters[['DAY_TYPE', 'Cluster', 'HOUR', 'OCCUPANCY_PCT']]\n",
    "linechart_data['Cluster'] = np.where(linechart_data['Cluster'] == 0, 'City Centre',\n",
    "                                    np.where(linechart_data['Cluster'] == 1, 'Grangegorman',\n",
    "                                            np.where(linechart_data['Cluster'] == 2, 'Transport Hubs',\n",
    "                                                    np.where(linechart_data['Cluster'] == 3, 'Docklands & South City', 'Outer Suburbs'))))\n",
    "\n",
    "#Weekday\n",
    "linechart_data_weekday = linechart_data[linechart_data['DAY_TYPE'] == 'Weekday']\n",
    "linechart_data_weekday = linechart_data_weekday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_weekday  = linechart_data_weekday.reset_index()\n",
    "y1 = linechart_data_weekday['OCCUPANCY_PCT'].values\n",
    "x1 = linechart_data_weekday['HOUR'].values\n",
    "labels1 = linechart_data_weekday['Cluster'].values\n",
    "colours1 = linechart_data_weekday['Cluster'].values\n",
    "df1 = pd.DataFrame(dict(x=x1, y=y1, label=labels1))\n",
    "groups1 = df1.groupby('label')\n",
    "\n",
    "#Saturday\n",
    "linechart_data_saturday = linechart_data[linechart_data['DAY_TYPE'] == 'Saturday']\n",
    "linechart_data_saturday = linechart_data_saturday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_saturday  = linechart_data_saturday.reset_index()\n",
    "y2 = linechart_data_saturday['OCCUPANCY_PCT'].values\n",
    "x2 = linechart_data_saturday['HOUR'].values\n",
    "labels2 = linechart_data_saturday['Cluster'].values\n",
    "colours2 = linechart_data_saturday['Cluster'].values\n",
    "df2 = pd.DataFrame(dict(x=x2, y=y2, label=labels2))\n",
    "groups2 = df2.groupby('label')\n",
    "\n",
    "#Sunday\n",
    "linechart_data_sunday = linechart_data[linechart_data['DAY_TYPE'] == 'Sunday']\n",
    "linechart_data_sunday = linechart_data_sunday.groupby(['HOUR', 'Cluster'])['OCCUPANCY_PCT'].mean()\n",
    "linechart_data_sunday  = linechart_data_sunday.reset_index()\n",
    "y3 = linechart_data_sunday['OCCUPANCY_PCT'].values\n",
    "x3 = linechart_data_sunday['HOUR'].values\n",
    "labels3 = linechart_data_sunday['Cluster'].values\n",
    "colours3 = linechart_data_sunday['Cluster'].values\n",
    "df3 = pd.DataFrame(dict(x=x3, y=y3, label=labels3))\n",
    "groups3 = df3.groupby('label')\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for name, group in groups1:\n",
    "    axs[0].plot(group.x, group.y, label=name)\n",
    "    axs[0].set_title('Weekday')\n",
    "    axs[0].set_xlabel('Hour')\n",
    "    axs[0].set_ylabel('Occupancy %')\n",
    "    #fig.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "\n",
    "for name, group in groups2:\n",
    "    axs[1].plot(group.x, group.y, label=name)\n",
    "    axs[1].set_title('Saturday')\n",
    "    axs[1].set_xlabel('Hour')\n",
    "    axs[1].set_ylabel('Occupancy %')\n",
    "    \n",
    "\n",
    "for name, group in groups3:\n",
    "    axs[2].plot(group.x, group.y, label=name)\n",
    "    axs[2].set_title('Sunday')\n",
    "    axs[2].set_xlabel('Hour')\n",
    "    axs[2].set_ylabel('Occupancy %')\n",
    "    axs[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of Stations\n",
    "join_table= merged_with_clusters.groupby(['STATION ID','NAME', 'DATE']).agg(rain=('rain', 'sum'), TOTAL_CHANGES=('BIKE_ARR_DEP_ABS', 'sum'))\n",
    "join_table =join_table.reset_index()\n",
    "join_table['WET/DRY DAY'] = np.where(join_table['rain'] > 3, \"Wet\", \"Dry\")\n",
    "join_table = join_table.drop(['rain'], axis = 1)\n",
    "join_table =join_table.reset_index()\n",
    "merged_with_clusters_wetdry = pd.merge(merged_with_clusters, join_table, on = ['STATION ID', 'NAME', 'DATE'], how = 'left')\n",
    "\n",
    "wetday_df= merged_with_clusters_wetdry.groupby(['STATION ID', 'NAME', 'WET/DRY DAY']).agg(AVG_CHANGES=('TOTAL_CHANGES', 'mean'))\n",
    "wetday_df =wetday_df.reset_index()\n",
    "difference_df = wetday_df.pivot(index=['NAME'], columns='WET/DRY DAY', values='AVG_CHANGES').reset_index()\n",
    "difference_df['Change'] = difference_df['Dry'] - difference_df['Wet']\n",
    "difference_df.sort_values(by = 'Change', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y = wetday_df['AVG_CHANGES'].values\n",
    "x = wetday_df['STATION ID'].values\n",
    "labels = wetday_df['WET/DRY DAY'].values\n",
    "colours = wetday_df['WET/DRY DAY'].values\n",
    "df = pd.DataFrame(dict(x=x, y=y, label=labels))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 10))\n",
    "#ax.set_color_cycle(colors)\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y,  marker='o',  linestyle='', ms=15, label=name)\n",
    "ax.legend(numpoints=1, loc='upper left')\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Avg Rentals/Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Occupancy Percentage Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_classifier_data = merged_with_clusters[merged_with_clusters['REBALANCING'] < 1] #exclude days where rebalancing took place\n",
    "ml_classifier_data = ml_classifier_data[['STATION ID', 'OCCUPANCY_PCT' , 'dry', 'warm', 'DAY_NUMBER', 'HOUR', 'MONTH']]\n",
    "\n",
    "\n",
    "def bin_occupancy(x):\n",
    "    if x < 0.1:\n",
    "        return 0\n",
    "    elif x < 0.1:\n",
    "        return 0.1\n",
    "    elif x < 0.2:\n",
    "        return 0.1\n",
    "    elif x < 0.3:\n",
    "        return 0.1\n",
    "    elif x < 0.4:\n",
    "        return 0.1\n",
    "    elif x < 0.5:\n",
    "        return 0.1\n",
    "    elif x < 0.6:\n",
    "        return 0.1\n",
    "    elif x < 0.7:\n",
    "        return 0.1\n",
    "    elif x < 0.8:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.2\n",
    "\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data['OCCUPANCY_PCT'].apply(bin_occupancy)\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data[\"OCC_GROUP\"] * 10\n",
    "ml_classifier_data[\"OCC_GROUP\"] = ml_classifier_data[\"OCC_GROUP\"].astype(int)\n",
    "ml_classifier_data.dropna(inplace = True)\n",
    "msk = np.random.rand(len(ml_classifier_data)) < 0.8\n",
    "train = ml_classifier_data[msk]\n",
    "test = ml_classifier_data[~msk]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "X_train = train.drop(['OCCUPANCY_PCT', \"OCC_GROUP\"], axis = 1)\n",
    "X_test = test.drop(['OCCUPANCY_PCT', \"OCC_GROUP\"], axis = 1)\n",
    "Y_train = train[[\"OCC_GROUP\"]] \n",
    "Y_test = test[[\"OCC_GROUP\"]]\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "#pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "print(sklearn.metrics.classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show feature importances \n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=['STATION ID','DRY', 'WARM', 'DAY_NUMBER', 'HOUR', 'MONTH']).sort_values(ascending=False)\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
